{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "def main():\n",
        "  text=input(\"Enter your text:\")\n",
        "  print(predict_sentiment(text))\n",
        "\n",
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDDT2Nzmhp-5",
        "outputId": "46405472-73e8-4d88-e71d-57f7baaed960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text:ragunath is a bad boy\n",
            "Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer=SentimentIntensityAnalyzer()\n",
        "text=input(\"Enter the text: \")\n",
        "sentiment=analyzer.polarity_scores(text)\n",
        "print(\"SEntimental score\",sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY_2WzW5kHVm",
        "outputId": "225cab0c-c712-4418-c890-496ce9750e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: it is a best movie i ever watched\n",
            "SEntimental score {'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.6369}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i-HcHDnlDgD",
        "outputId": "882fa506-6adb-4f0b-8bcc-2cedfd09757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.7.4)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from textblob import TextBlob\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Sample text\n",
        "text=input(\"Enter your text:\")\n",
        "\n",
        "# Tokenize sentences\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"Sentences:\", sentences)\n",
        "\n",
        "# Tokenize words\n",
        "words = word_tokenize(text)\n",
        "print(\"Words:\", words)\n",
        "\n",
        "# POS tagging\n",
        "pos_tags = pos_tag(words)\n",
        "print(\"POS Tags:\", pos_tags)\n",
        "\n",
        "# Lemmatization\n",
        "lemmatized_words = []\n",
        "for word, tag in pos_tags:\n",
        "    wn_tag = get_wordnet_pos(tag)\n",
        "    lemmatized_word = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "    lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n",
        "\n",
        "# Sentiment Analysis\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment\n",
        "print(\"Sentiment Analysis:\")\n",
        "print(f\"  Polarity: {sentiment.polarity}\")\n",
        "print(f\"  Subjectivity: {sentiment.subjectivity}\")\n",
        "\n",
        "# Explanation of Sentiment Analysis\n",
        "if sentiment.polarity > 0:\n",
        "    print(\"The sentiment of the text is positive.\")\n",
        "elif sentiment.polarity < 0:\n",
        "    print(\"The sentiment of the text is negative.\")\n",
        "else:\n",
        "    print(\"The sentiment of the text is neutral.\")\n"
      ],
      "metadata": {
        "id": "U0gqnEWNor-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9be63db-4329-4ee1-fddb-240b1c8542d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text:reading books is a good habit\n",
            "Sentences: ['reading books is a good habit']\n",
            "Words: ['reading', 'books', 'is', 'a', 'good', 'habit']\n",
            "POS Tags: [('reading', 'VBG'), ('books', 'NNS'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('habit', 'NN')]\n",
            "Lemmatized Words: ['read', 'book', 'be', 'a', 'good', 'habit']\n",
            "Sentiment Analysis:\n",
            "  Polarity: 0.7\n",
            "  Subjectivity: 0.6000000000000001\n",
            "The sentiment of the text is positive.\n"
          ]
        }
      ]
    }
  ]
}